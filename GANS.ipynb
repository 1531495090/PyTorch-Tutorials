{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Step [200/600], d_loss: 0.0452, g_loss: 4.3386 \n",
      "Epoch [0/10], Step [400/600], d_loss: 0.1360, g_loss: 4.9729 \n",
      "Epoch [0/10], Step [600/600], d_loss: 0.0328, g_loss: 5.3808 \n",
      "Epoch [1/10], Step [200/600], d_loss: 0.0616, g_loss: 5.6563 \n",
      "Epoch [1/10], Step [400/600], d_loss: 0.2106, g_loss: 3.5196 \n",
      "Epoch [1/10], Step [600/600], d_loss: 0.3836, g_loss: 4.4486 \n",
      "Epoch [2/10], Step [200/600], d_loss: 0.1566, g_loss: 3.4256 \n",
      "Epoch [2/10], Step [400/600], d_loss: 1.1676, g_loss: 2.7942 \n",
      "Epoch [2/10], Step [600/600], d_loss: 0.1919, g_loss: 4.2086 \n",
      "Epoch [3/10], Step [200/600], d_loss: 0.2330, g_loss: 3.6334 \n",
      "Epoch [3/10], Step [400/600], d_loss: 0.8132, g_loss: 3.4572 \n",
      "Epoch [3/10], Step [600/600], d_loss: 0.1976, g_loss: 3.9961 \n",
      "Epoch [4/10], Step [200/600], d_loss: 0.6469, g_loss: 3.4096 \n",
      "Epoch [4/10], Step [400/600], d_loss: 0.3115, g_loss: 3.8466 \n",
      "Epoch [4/10], Step [600/600], d_loss: 0.1797, g_loss: 3.2961 \n",
      "Epoch [5/10], Step [200/600], d_loss: 0.4727, g_loss: 5.3163 \n",
      "Epoch [5/10], Step [400/600], d_loss: 0.2535, g_loss: 3.6409 \n",
      "Epoch [5/10], Step [600/600], d_loss: 0.5925, g_loss: 3.4327 \n",
      "Epoch [6/10], Step [200/600], d_loss: 0.5229, g_loss: 3.4864 \n",
      "Epoch [6/10], Step [400/600], d_loss: 0.3635, g_loss: 4.3978 \n",
      "Epoch [6/10], Step [600/600], d_loss: 0.3305, g_loss: 3.5535 \n",
      "Epoch [7/10], Step [200/600], d_loss: 0.1542, g_loss: 3.9531 \n",
      "Epoch [7/10], Step [400/600], d_loss: 0.1438, g_loss: 3.3679 \n",
      "Epoch [7/10], Step [600/600], d_loss: 0.2528, g_loss: 5.8108 \n",
      "Epoch [8/10], Step [200/600], d_loss: 0.1854, g_loss: 5.6493 \n",
      "Epoch [8/10], Step [400/600], d_loss: 0.3392, g_loss: 5.4587 \n",
      "Epoch [8/10], Step [600/600], d_loss: 0.0764, g_loss: 4.8581 \n",
      "Epoch [9/10], Step [200/600], d_loss: 0.1503, g_loss: 4.1301 \n",
      "Epoch [9/10], Step [400/600], d_loss: 0.1419, g_loss: 5.1282 \n",
      "Epoch [9/10], Step [600/600], d_loss: 0.1980, g_loss: 5.8345 \n"
     ]
    }
   ],
   "source": [
    "random_size = 64 \n",
    "hidden_size = 256 \n",
    "image_size = 784\n",
    "num_epoch = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "sample_dir = 'samples'\n",
    "\n",
    "\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean =(0.5,0.5,0.5),# this is for RGB image(3 channel)\n",
    "                        std = (0.5,0.5,0.5))])\n",
    "\n",
    "data = torchvision.datasets.MNIST(root = 'Data', transform = transform, train=True, download = True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset = data, shuffle = True, batch_size = batch_size)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, hidden_size)\n",
    "        self.relu = nn.LeakyReLU(0.2)#this is the negative slope. \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return (out)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, random_size, hidden_size, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(random_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, image_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        return(out)\n",
    "    \n",
    "model_d = Discriminator(image_size, hidden_size).to(device)\n",
    "model_g = Generator(random_size, hidden_size, image_size).to(device)\n",
    "\n",
    "criterion = nn.BCELoss() #using cross entropy loss\n",
    "optimizer_d = torch.optim.Adam(model_d.parameters(), lr = learning_rate)\n",
    "optimizer_g = torch.optim.Adam(model_g.parameters(), lr = learning_rate)\n",
    "\n",
    "total_step = len(data_loader)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        \n",
    "        #To train the Discriminator\n",
    "        output_d_real = model_d(images)\n",
    "        d_real_loss = criterion(output_d_real, real_labels)\n",
    "        \n",
    "        z = torch.randn(batch_size, random_size).to(device)\n",
    "        fake_images = model_g(z)\n",
    "        output_d_fake = model_d(fake_images)\n",
    "        d_fake_loss = criterion(output_d_fake, fake_labels)\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        \n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()#this is going to update only parameters of discriminator\n",
    "        \n",
    "        #to train the generator\n",
    "        z = torch.randn(batch_size, random_size).to(device)\n",
    "        fake_images = model_g(z)\n",
    "        outputs = model_d(fake_images)\n",
    "        \n",
    "        #to train the generator the output of this should be compared with real_labels. \n",
    "        #so we compare the output by real label. \n",
    "        \n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f} ' \n",
    "                  .format(epoch, num_epoch, i+1, total_step, d_loss.item(), g_loss.item()))\n",
    "    if (epoch == num_epoch-1):\n",
    "        fake_image = fake_images.reshape(fake_images.size(0),1,28,28)\n",
    "        save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_g.state_dict(), 'G.ckpt')  #we are saving only the parameters\n",
    "torch.save(model_d.state_dict(), 'D.ckpt')  #if memory is not an issue then better save the whole model. \n",
    "torch.save(model_g, 'G_model.ckpt')#one more important thing is that the device which you have used to train will be only used for testing also(cuda or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[ 0.0204, -0.0074,  0.0106,  ..., -0.0078,  0.0017,  0.0054],\n",
      "        [ 0.0491, -0.0023,  0.0294,  ...,  0.0021, -0.0113,  0.0027],\n",
      "        [ 0.0573, -0.0045,  0.0484,  ..., -0.0216, -0.0126, -0.0022],\n",
      "        ...,\n",
      "        [-0.0088, -0.0236, -0.0427,  ...,  0.0254,  0.0002, -0.0157],\n",
      "        [-0.0049,  0.0072,  0.0023,  ..., -0.0027,  0.0008,  0.0084],\n",
      "        [ 0.0249, -0.0165,  0.0199,  ...,  0.0613, -0.0519, -0.0095]],\n",
      "       device='cuda:0')), ('fc1.bias', tensor([-0.0935, -0.1042, -0.0458, -0.1942, -0.1662, -0.1799, -0.1838,  0.0796,\n",
      "        -0.1442, -0.2187, -0.1250, -0.1063, -0.1021, -0.1250, -0.0782, -0.2127,\n",
      "        -0.1127, -0.1682, -0.0990, -0.0644, -0.0494, -0.1956, -0.0590, -0.0468,\n",
      "        -0.1630, -0.0769, -0.1232, -0.0913, -0.0860, -0.1368, -0.0371, -0.0885,\n",
      "        -0.0736, -0.1410, -0.1843, -0.0407, -0.2049, -0.1075, -0.0249, -0.0482,\n",
      "        -0.0548, -0.0398, -0.0879, -0.0353, -0.2352, -0.1684, -0.1707, -0.1164,\n",
      "        -0.0800, -0.0319, -0.0514, -0.1349, -0.1283, -0.1729, -0.1164, -0.0999,\n",
      "        -0.1893, -0.1635, -0.2028, -0.0941, -0.1761, -0.0672, -0.1793, -0.1666,\n",
      "        -0.1821, -0.2158, -0.0844, -0.1840, -0.0303, -0.2316, -0.1125, -0.0538,\n",
      "        -0.2100, -0.1143, -0.1565, -0.2016, -0.1728, -0.2313, -0.0472, -0.1172,\n",
      "        -0.0825, -0.0648, -0.0684, -0.1542, -0.0715, -0.0310, -0.0850, -0.1648,\n",
      "        -0.0563, -0.0818, -0.0682, -0.1277, -0.1691, -0.1561, -0.0501,  0.0446,\n",
      "        -0.1529, -0.0630, -0.1402, -0.1311, -0.1183, -0.1901, -0.1478, -0.0948,\n",
      "        -0.2099, -0.0782, -0.0953, -0.1590, -0.2191, -0.1385, -0.0625, -0.2217,\n",
      "        -0.1918, -0.1955, -0.2050, -0.0477, -0.0392, -0.0238, -0.2103, -0.1548,\n",
      "        -0.1002, -0.0451, -0.1933, -0.1141, -0.0313, -0.1269, -0.0959, -0.1358,\n",
      "        -0.0873, -0.1374, -0.1114, -0.1889, -0.0724, -0.1071, -0.0923, -0.1055,\n",
      "        -0.0649, -0.0380, -0.1781, -0.1872, -0.0498, -0.0100, -0.0705, -0.1470,\n",
      "        -0.1411, -0.1161, -0.1436, -0.0814, -0.1162, -0.0795, -0.0896, -0.1049,\n",
      "         0.0579, -0.0763, -0.1580, -0.0318, -0.2293, -0.0401, -0.0820, -0.1420,\n",
      "        -0.0569, -0.0433, -0.0806, -0.0797, -0.1364, -0.0448, -0.2215, -0.1989,\n",
      "        -0.0537, -0.2223, -0.1914, -0.0522, -0.0538, -0.1702, -0.1559, -0.0756,\n",
      "        -0.1500, -0.0536, -0.0593, -0.0975, -0.0493, -0.2211, -0.0917, -0.0361,\n",
      "        -0.0585, -0.2104, -0.1718, -0.0667, -0.1911, -0.0942, -0.0463, -0.0556,\n",
      "        -0.0421, -0.0948, -0.0459, -0.1007, -0.1941,  0.0123, -0.1455, -0.1318,\n",
      "        -0.1376, -0.1491, -0.1021, -0.1023, -0.0572, -0.1994, -0.1569, -0.1394,\n",
      "        -0.1620, -0.0806, -0.0007, -0.0681, -0.2161, -0.0992, -0.0911, -0.0345,\n",
      "        -0.1358, -0.1533, -0.0931, -0.0004, -0.0559, -0.0642, -0.1594, -0.0670,\n",
      "        -0.0226, -0.0763, -0.0963, -0.1268, -0.0691, -0.0805, -0.0334, -0.0300,\n",
      "        -0.1667, -0.2015, -0.1083, -0.1967, -0.0505,  0.0412, -0.0348, -0.0584,\n",
      "        -0.1462, -0.1407, -0.1125, -0.0682, -0.2115, -0.0895, -0.0277, -0.0548,\n",
      "        -0.1531, -0.0463, -0.1328, -0.1178, -0.1609, -0.0373, -0.1322, -0.1329],\n",
      "       device='cuda:0')), ('fc2.weight', tensor([[ 0.0054,  0.0027,  0.0045,  ...,  0.0270,  0.0058,  0.0159],\n",
      "        [ 0.0504,  0.0559,  0.0623,  ...,  0.0716,  0.0389,  0.0516],\n",
      "        [ 0.1473,  0.0806,  0.2018,  ..., -0.1838, -0.0065,  0.0061],\n",
      "        ...,\n",
      "        [-0.0606, -0.0019, -0.0537,  ...,  0.0489, -0.0370,  0.0819],\n",
      "        [ 0.0015, -0.0233,  0.0342,  ...,  0.0753, -0.0566, -0.0523],\n",
      "        [ 0.0592, -0.0628, -0.0447,  ...,  0.1201, -0.0358, -0.0364]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([-0.0613,  0.0255,  0.0234,  0.0403,  0.0448, -0.0202, -0.0043, -0.0022,\n",
      "         0.0154,  0.1299,  0.0915, -0.0365, -0.0253,  0.0210,  0.0232, -0.0541,\n",
      "         0.0299, -0.0507,  0.1946,  0.0283,  0.1019,  0.0235, -0.0135,  0.2176,\n",
      "         0.1342,  0.0415, -0.0676, -0.0143,  0.0753, -0.0497, -0.0361,  0.0234,\n",
      "         0.0038, -0.0334, -0.0020,  0.0613,  0.0747,  0.0216,  0.0299,  0.0003,\n",
      "         0.0227, -0.0159,  0.1137,  0.0172, -0.0623,  0.0321,  0.0143,  0.0488,\n",
      "         0.0201,  0.2275, -0.0076,  0.0022, -0.0235,  0.0214,  0.0854,  0.1174,\n",
      "        -0.0663,  0.0458,  0.1916,  0.0743,  0.0154,  0.0006,  0.0107, -0.0308,\n",
      "         0.0436, -0.0395, -0.0699, -0.0316,  0.0657,  0.0155, -0.0417,  0.1151,\n",
      "         0.0069,  0.0391, -0.0326,  0.0447,  0.0177,  0.0277,  0.0108,  0.0779,\n",
      "         0.1404,  0.0823, -0.0117, -0.0610, -0.0597,  0.0538,  0.0866,  0.0464,\n",
      "         0.0404, -0.0091, -0.0101,  0.0424, -0.0205, -0.0005,  0.0183,  0.0564,\n",
      "         0.0060, -0.0331,  0.0583, -0.0688,  0.0320,  0.0379, -0.0457,  0.1410,\n",
      "         0.0142, -0.0057, -0.0636,  0.0823,  0.0742,  0.1572, -0.0028, -0.0360,\n",
      "        -0.0541,  0.0942,  0.0561, -0.0129,  0.0030,  0.0319,  0.0396,  0.0526,\n",
      "         0.0110,  0.0197, -0.0340, -0.0593,  0.0911,  0.0028,  0.1351,  0.0855,\n",
      "        -0.0691,  0.0818,  0.0417,  0.0495, -0.0045, -0.0222, -0.0429, -0.0858,\n",
      "         0.0124,  0.0328,  0.0094,  0.0196,  0.0065,  0.1674, -0.0095,  0.0469,\n",
      "        -0.0609,  0.0353, -0.0831,  0.0322,  0.0403, -0.0651,  0.0871,  0.0174,\n",
      "        -0.0338,  0.0344,  0.1531, -0.0535,  0.0475,  0.0497,  0.0676, -0.0058,\n",
      "        -0.0100,  0.0161,  0.0471, -0.0052, -0.0117, -0.0256,  0.1153, -0.0003,\n",
      "        -0.0327, -0.0346, -0.0033,  0.0849,  0.1284, -0.0697,  0.0091,  0.1899,\n",
      "        -0.0095, -0.0148,  0.0436, -0.0328, -0.0182,  0.1387,  0.0127, -0.0460,\n",
      "         0.0199,  0.0710,  0.2011,  0.0194,  0.0514,  0.0401,  0.0085,  0.0744,\n",
      "         0.0295,  0.0261,  0.0152,  0.0006,  0.0537, -0.0319, -0.0401,  0.1119,\n",
      "        -0.0353,  0.0911,  0.1575,  0.0163,  0.0441,  0.0067,  0.1541, -0.0705,\n",
      "         0.0314, -0.0472, -0.0228,  0.0579,  0.0073,  0.0103, -0.0048,  0.0111,\n",
      "        -0.0904,  0.0963, -0.0436, -0.0320, -0.0027, -0.0321, -0.0306,  0.0791,\n",
      "        -0.0038, -0.0367,  0.0333,  0.0738,  0.0295, -0.0086, -0.0035,  0.0154,\n",
      "         0.0158,  0.0198, -0.0069,  0.0206, -0.0131, -0.0267,  0.0191,  0.0416,\n",
      "         0.0464,  0.1962, -0.0451, -0.0161,  0.0952,  0.0243,  0.0390, -0.0318,\n",
      "        -0.0007,  0.0075,  0.0509,  0.1550, -0.0577,  0.0101,  0.0446,  0.0380],\n",
      "       device='cuda:0')), ('fc3.weight', tensor([[-0.1492, -0.0610,  0.0273,  ...,  0.0452,  0.0148, -0.0877],\n",
      "        [-0.0954,  0.0590, -0.0632,  ...,  0.0868, -0.0370, -0.0224],\n",
      "        [-0.0201, -0.1648, -0.0643,  ..., -0.0797, -0.0438, -0.1373],\n",
      "        ...,\n",
      "        [-0.0300,  0.0006, -0.0890,  ..., -0.0369, -0.0312, -0.1059],\n",
      "        [-0.0237, -0.0533, -0.1081,  ..., -0.0454, -0.0993, -0.0991],\n",
      "        [ 0.0216, -0.0690, -0.0440,  ..., -0.0580, -0.0363,  0.0306]],\n",
      "       device='cuda:0')), ('fc3.bias', tensor([-0.0495, -0.0753, -0.1018, -0.1297, -0.0808, -0.0899, -0.0717, -0.0261,\n",
      "        -0.1950, -0.0722, -0.0018, -0.1645, -0.0691, -0.1630, -0.1245, -0.0792,\n",
      "        -0.1737, -0.1028, -0.0984, -0.0683, -0.0858, -0.1461, -0.0690, -0.0786,\n",
      "        -0.1512, -0.0947, -0.1457, -0.1076, -0.1455, -0.1183, -0.1169, -0.0483,\n",
      "        -0.0628, -0.0445, -0.1277, -0.0741, -0.0473, -0.1675, -0.0188, -0.0737,\n",
      "        -0.1186, -0.1169, -0.0791, -0.0919, -0.0399, -0.1711, -0.1444, -0.0842,\n",
      "        -0.1263, -0.1608, -0.1647, -0.1731, -0.1459, -0.0845, -0.1094, -0.0945,\n",
      "        -0.0969, -0.0305, -0.1084, -0.1125, -0.1405, -0.0451, -0.1467, -0.1103,\n",
      "        -0.0954, -0.1582, -0.1340, -0.0864, -0.1032, -0.0927, -0.0533, -0.0837,\n",
      "        -0.1102, -0.0625, -0.1556, -0.1360, -0.0923, -0.0932, -0.1506, -0.1065,\n",
      "        -0.0941, -0.0671, -0.0627, -0.0782, -0.1808, -0.0357, -0.0719, -0.1152,\n",
      "        -0.0477, -0.0872, -0.0718, -0.0808, -0.1135, -0.0599, -0.0797, -0.0683,\n",
      "        -0.1084, -0.0943, -0.0658, -0.0828, -0.0633, -0.0377, -0.0336, -0.0021,\n",
      "        -0.0502, -0.0409, -0.0723, -0.0773, -0.1398, -0.1096, -0.0805, -0.1116,\n",
      "        -0.0577, -0.0628, -0.0725, -0.0844, -0.1160, -0.1612, -0.1329, -0.1452,\n",
      "        -0.0627, -0.0901, -0.0860, -0.0576, -0.0645, -0.0425, -0.1020, -0.0693,\n",
      "         0.0170, -0.0802, -0.0459, -0.0321, -0.0536, -0.0853, -0.1067, -0.0649,\n",
      "        -0.0519, -0.1066, -0.0482, -0.1414, -0.0933, -0.0935, -0.0364, -0.1624,\n",
      "        -0.1391, -0.0901, -0.1109, -0.0875, -0.0292, -0.1122, -0.0158, -0.0611,\n",
      "        -0.1119, -0.0657, -0.0275, -0.0426, -0.0350, -0.0455,  0.0029, -0.0134,\n",
      "        -0.0481, -0.1307, -0.0874, -0.0784, -0.1012, -0.0738, -0.1786, -0.0606,\n",
      "        -0.1576, -0.1542, -0.0877, -0.0811, -0.1092, -0.0614, -0.0668, -0.0637,\n",
      "        -0.1534, -0.1101, -0.1283, -0.0294,  0.0270, -0.0448, -0.0605, -0.0341,\n",
      "        -0.0144,  0.0656,  0.0029, -0.0418, -0.0950, -0.0049, -0.1508, -0.1189,\n",
      "        -0.1199, -0.0539, -0.0754, -0.1613, -0.1241, -0.0837, -0.1362, -0.0862,\n",
      "        -0.0681, -0.1520, -0.1018, -0.0371, -0.1295, -0.0869,  0.0084, -0.0595,\n",
      "         0.0434, -0.0300,  0.0393, -0.0405,  0.0257, -0.0580, -0.0044,  0.0395,\n",
      "        -0.0179, -0.0410, -0.0828, -0.0539, -0.0777, -0.1119, -0.0629, -0.1637,\n",
      "        -0.1290, -0.0681, -0.0824, -0.1001, -0.1623, -0.0716, -0.0170, -0.0377,\n",
      "        -0.0347, -0.0031, -0.0602, -0.0649, -0.0473, -0.0073, -0.0377,  0.0406,\n",
      "        -0.0378, -0.0315, -0.0563, -0.0243, -0.0165, -0.0483, -0.0028, -0.1015,\n",
      "        -0.1135, -0.1458, -0.0735, -0.0621, -0.0443, -0.1047, -0.0520, -0.0725,\n",
      "        -0.0252, -0.0597, -0.1237, -0.0774, -0.1050, -0.0707, -0.0348,  0.0258,\n",
      "        -0.0021, -0.0772, -0.0384,  0.0000, -0.0455, -0.0285,  0.0125,  0.0076,\n",
      "        -0.0552, -0.0023, -0.1359, -0.1005, -0.1599, -0.1048, -0.0777, -0.1158,\n",
      "        -0.1428, -0.0697, -0.1021, -0.0762, -0.0656, -0.1568, -0.1429, -0.1098,\n",
      "        -0.0479, -0.0567, -0.0390, -0.0003, -0.0059, -0.0715, -0.0610,  0.0076,\n",
      "        -0.0587, -0.0451,  0.0532, -0.0642, -0.0571, -0.0686, -0.0952, -0.0619,\n",
      "        -0.0370, -0.0661, -0.1557, -0.1391, -0.0372, -0.1006, -0.1214, -0.1439,\n",
      "        -0.0581, -0.1089, -0.1090, -0.0763, -0.1275, -0.0132,  0.0262, -0.0095,\n",
      "        -0.0640, -0.0581, -0.0469,  0.0134, -0.0519,  0.0254,  0.0194, -0.0601,\n",
      "         0.0174,  0.0082, -0.0277, -0.1532, -0.0884, -0.0780, -0.0705, -0.1560,\n",
      "        -0.1525, -0.1213, -0.0884, -0.0983, -0.0565, -0.0926, -0.0833, -0.0992,\n",
      "        -0.0435, -0.0060, -0.0066,  0.0290, -0.0313, -0.0073, -0.0626, -0.0683,\n",
      "         0.0115, -0.0551, -0.0417, -0.0461, -0.0457, -0.0761, -0.0442, -0.0850,\n",
      "        -0.1374, -0.0561, -0.0616, -0.1494, -0.0673, -0.1393, -0.1165, -0.1097,\n",
      "        -0.0826, -0.1180, -0.1240, -0.0231, -0.1113, -0.0951, -0.0814, -0.0250,\n",
      "         0.0568, -0.0764,  0.0439, -0.0377, -0.0147, -0.0587, -0.0361, -0.0409,\n",
      "        -0.0533, -0.0623, -0.0574, -0.0680, -0.1577, -0.0608, -0.1227, -0.0664,\n",
      "        -0.0492, -0.0253, -0.0981, -0.1566, -0.1305, -0.0976, -0.0666, -0.0709,\n",
      "        -0.0690,  0.0168,  0.0155, -0.0132, -0.0557, -0.0590,  0.0133,  0.0172,\n",
      "        -0.0057,  0.0142, -0.0616,  0.0313, -0.0614, -0.0614, -0.0868, -0.1222,\n",
      "        -0.0607, -0.0658, -0.0679, -0.0939, -0.0675, -0.0819, -0.0957, -0.0196,\n",
      "        -0.0359,  0.0003, -0.0582,  0.0188, -0.0447, -0.0672, -0.0812, -0.0691,\n",
      "        -0.0294, -0.0126,  0.0224, -0.0445, -0.0440, -0.0526, -0.0238, -0.0778,\n",
      "        -0.0596, -0.0177, -0.1127, -0.0411, -0.0364, -0.1130, -0.0190, -0.1635,\n",
      "        -0.0529, -0.1386, -0.0529, -0.0634, -0.0687, -0.1303, -0.0743, -0.0993,\n",
      "        -0.0521,  0.0080, -0.0363, -0.1049, -0.0082, -0.0069, -0.0540, -0.0780,\n",
      "        -0.0732, -0.0711, -0.0123, -0.0704, -0.0065, -0.0536, -0.0651, -0.0350,\n",
      "        -0.0312, -0.1396, -0.1007, -0.1945, -0.1277, -0.0723, -0.0737, -0.1137,\n",
      "        -0.1214, -0.0527, -0.0987, -0.0337,  0.0242, -0.0234,  0.0155, -0.0550,\n",
      "        -0.0018, -0.0844, -0.0503, -0.0457,  0.0232,  0.0094, -0.0377, -0.0655,\n",
      "         0.0121, -0.0056, -0.0936, -0.0600, -0.0784, -0.0625, -0.0906, -0.1779,\n",
      "        -0.0392, -0.0480, -0.1765, -0.1239, -0.1365, -0.0597, -0.1157, -0.0397,\n",
      "        -0.0230,  0.0067, -0.0151, -0.0020, -0.0259, -0.0407,  0.0180, -0.0759,\n",
      "        -0.0022,  0.0182, -0.0514,  0.0146, -0.0851, -0.0291, -0.1127, -0.1504,\n",
      "        -0.0181, -0.0633, -0.1111, -0.0511, -0.0927, -0.0585, -0.1733, -0.1119,\n",
      "        -0.1038, -0.0060, -0.0104, -0.0111, -0.0656, -0.0311, -0.0659,  0.0057,\n",
      "        -0.0897, -0.0044, -0.0406, -0.0276, -0.0335,  0.0637,  0.0086, -0.0104,\n",
      "        -0.0926, -0.1075, -0.0815, -0.0704, -0.0574, -0.1384, -0.0421, -0.0347,\n",
      "        -0.0546, -0.0930, -0.0284,  0.0121, -0.1460, -0.0566, -0.0413, -0.0405,\n",
      "        -0.0011,  0.0398,  0.0613,  0.0261,  0.0400, -0.0488,  0.0306, -0.0308,\n",
      "        -0.0033,  0.0175, -0.0691, -0.0233, -0.1091, -0.0437, -0.0323, -0.1149,\n",
      "        -0.1263, -0.1460, -0.1255, -0.0784, -0.1691, -0.1634, -0.0452, -0.0840,\n",
      "        -0.1441, -0.0699, -0.0682, -0.0846, -0.0508, -0.0078, -0.0112, -0.0291,\n",
      "         0.0001, -0.0060,  0.0028,  0.0148, -0.0226,  0.0050,  0.0116, -0.0729,\n",
      "        -0.1043, -0.1221, -0.1068, -0.0677, -0.0686, -0.1528, -0.0924, -0.0917,\n",
      "        -0.1638, -0.0720, -0.1306, -0.0677, -0.0410, -0.0805, -0.0517, -0.0264,\n",
      "         0.0253,  0.0176,  0.0508, -0.0238, -0.0163, -0.0494,  0.0370, -0.0054,\n",
      "        -0.0294, -0.0670, -0.0519, -0.0266, -0.1198, -0.1045, -0.0536, -0.1169,\n",
      "        -0.0656, -0.1450, -0.0355, -0.1734, -0.1174, -0.1359, -0.0878, -0.0910,\n",
      "        -0.0674, -0.1485, -0.1274, -0.1138, -0.0268, -0.0785, -0.0718,  0.0313,\n",
      "         0.0096, -0.0599,  0.0167, -0.0691, -0.0530, -0.0660, -0.0199, -0.0642,\n",
      "        -0.0445, -0.1175, -0.1266, -0.0514, -0.1006, -0.0691, -0.0791, -0.1602,\n",
      "        -0.1240, -0.0632, -0.0994, -0.0819, -0.1630, -0.1339, -0.0880, -0.1443,\n",
      "        -0.1135, -0.0919,  0.0042, -0.0326, -0.0736, -0.0177, -0.0586, -0.1043,\n",
      "        -0.1317, -0.1194, -0.0921, -0.1348, -0.1052, -0.0792, -0.0624, -0.1434,\n",
      "        -0.0535, -0.1026,  0.0093, -0.1074, -0.1268, -0.1260, -0.1306, -0.1010,\n",
      "        -0.0998, -0.0889, -0.1103, -0.0083, -0.0359, -0.1584, -0.0740, -0.0945,\n",
      "        -0.1038, -0.1650, -0.1406, -0.1849, -0.1200, -0.0258, -0.1006, -0.0610,\n",
      "        -0.1058, -0.1442, -0.1418, -0.0416, -0.1072, -0.1030, -0.1174, -0.0761,\n",
      "        -0.1297, -0.1312, -0.0925, -0.0691, -0.1533, -0.1151, -0.0365, -0.1737,\n",
      "        -0.1309, -0.0977, -0.0754, -0.1685, -0.0951, -0.1467, -0.0965, -0.0891,\n",
      "        -0.0529, -0.1641, -0.1348, -0.1569, -0.0762, -0.1315, -0.0816, -0.0994,\n",
      "        -0.0551, -0.0692, -0.0588, -0.0627, -0.0755, -0.0168, -0.0666, -0.0842,\n",
      "        -0.1039, -0.1246, -0.1591, -0.1065, -0.0611, -0.1464, -0.1353, -0.0574,\n",
      "        -0.1507, -0.1154, -0.0858, -0.1069, -0.0858, -0.0860, -0.0593, -0.0755,\n",
      "        -0.1327, -0.0936, -0.0921, -0.1021, -0.1229, -0.1307, -0.1694, -0.0877],\n",
      "       device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "g_model = torch.load('G.ckpt') \n",
    "d_model = torch.load('D.ckpt')\n",
    "\n",
    "print(g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=784, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "tensor([[-0.8309, -0.7986, -0.9823,  ..., -0.9560, -0.9585, -0.8854],\n",
      "        [-0.9631, -0.9526, -0.9981,  ..., -0.9983, -0.9878, -0.9978],\n",
      "        [-0.8655, -0.7915, -0.9885,  ..., -0.9779, -0.9512, -0.9676],\n",
      "        ...,\n",
      "        [-0.8522, -0.8073, -0.9909,  ..., -0.9791, -0.9622, -0.9327],\n",
      "        [-0.6143, -0.6682, -0.9381,  ..., -0.8887, -0.8573, -0.6515],\n",
      "        [-0.9929, -0.9685, -1.0000,  ..., -0.9999, -0.9998, -0.9992]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('G_model.ckpt')\n",
    "print(model)\n",
    "z = torch.randn(batch_size, random_size).to(device) #to show that is stores model as well as parameters\n",
    "fake_images = model(z)\n",
    "print(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
